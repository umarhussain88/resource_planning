{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "from pathlib import Path\n",
    "from time import sleep\n",
    "\n",
    "sys.path.append(\n",
    "    os.path.abspath(\n",
    "        r\"S:\\Data\\Stores Payroll\\FY21\\99_Master Scripts (DO NOT EDIT)\\dB_Connector\"))\n",
    "\n",
    "from connector import *\n",
    "\n",
    "sys.path.append(\n",
    "    os.path.abspath(\n",
    "        r\"S:\\Data\\Stores Payroll\\FY21\\99_Master Scripts (DO NOT EDIT)\\common_functions\"))\n",
    "\n",
    "from halfords_functions import newest, halfords_week\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write all Training Credits to Database.\n",
    "\n",
    "* Same process as FY20, as we don't have compliance from the training team, we will do the following : \n",
    "\n",
    "* Delete two weeks of Training Data from our SQL database.\n",
    "\n",
    "* add these in.\n",
    "\n",
    "* Update Crosstab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read database to create an extract.\n",
    "\n",
    "extra_hours = pd.read_sql(\"SELECT * from extraHoursDetails\",engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fy21 dates.\n",
    "\n",
    "dates = pd.read_sql(\"SELECT * from fy21_calendar\", con=engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As today is 2019-09-26 we haven't started FY21 so we will be using a psuedo week number which is calculated\n",
      "from the distance of weeks from FY21\n",
      "We are -27 weeks away from FY21\n"
     ]
    }
   ],
   "source": [
    "file_name,week_,day_ = halfords_week(dates)\n",
    "print(f\"We are {week_} weeks away from FY21\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'S:\\Data\\Stores Payroll\\FY21\\02_Weekly Tasks\\Extra Hours\\sql_extracts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_hours.to_excel(f'{file_name}_extra_hours_extract.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_credits = r\"S:\\Data\\Stores Payroll\\FY21\\02_Weekly Tasks\\Extra Hours\\outputs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(newest(training_credits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-3f16290ee9b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Store'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Store'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzfill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df['Store'] = df['Store'].astype(str).str.zfill(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We get the current week and get the data from the previous two weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will be only writing in data greater than Week -29\n"
     ]
    }
   ],
   "source": [
    "print(f\"We will be only writing in data greater than Week {week_-2}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df.Week >= week_-2].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['EmployeeNumber'] = pd.to_numeric(df['EmployeeNumber'],errors='coerce').fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Metatypes for SQL Server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "xhtypes = {'Store'  : sa.types.VARCHAR(length=50),\n",
    "'Shop'              : sa.types.BIGINT,\n",
    "'Week'                : sa.types.BIGINT,\n",
    "'Hours'               : sa.types.FLOAT,\n",
    "'Reason'              : sa.types.VARCHAR(length=255),\n",
    "'CostCentre'          : sa.types.VARCHAR(length=255),\n",
    "'Type'                : sa.types.VARCHAR(length=50),\n",
    "'Rate'                : sa.types.FLOAT,\n",
    "'Owner'               : sa.types.VARCHAR(length=255),\n",
    "'BusinessFunction'    : sa.types.VARCHAR(length=255),\n",
    "'EmployeeNumber'      : sa.types.BIGINT,\n",
    "'Week Number'         : sa.types.BIGINT}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = newest(os.getcwd())    \n",
    "\n",
    "### this is the SQL Query to delete all records for the Hub & Training Team in the future, this allows us to track changes \n",
    "## and credit as needed, as compliance is an issue, the records are delete for the current week and two prior.\n",
    "# Outliers will be dealt in a seperate script. \n",
    "\n",
    "d = \"\"\"DELETE extraHoursDetails\n",
    "\n",
    "where BusinessFunction = 'Hub Team'\n",
    "\n",
    "and Week >=\"\"\" + str(int(week_)-2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_path = Path(newest(training_credits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Step - Write This to SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is this the file used for Training Credits Correct ? extra_hours_week_0_day_0 - Copy.xlsx all HUB Credits after Week -2 will be deleted [Y] or [N]y\n",
      "Added to SQL\n",
      "CrossTab Updated\n"
     ]
    }
   ],
   "source": [
    "## This code is quite shit, but works so I won't re-write it. Would recommend it be re-written so :\n",
    "## it's clear.\n",
    "\n",
    "while True:\n",
    "\n",
    "    cmd = input(f\"Is this the file used for Training Credits Correct ? {t_path.name} all HUB Credits after Week {week_-2} will be deleted [Y] or [N]\")\n",
    "    if cmd == 'y':\n",
    "        cnxn.execute(d)\n",
    "        cnxn.commit()\n",
    "        df.to_sql('extraHoursDetails',con=engine,schema='dbo',index=False,if_exists='append',dtype=xhtypes)\n",
    "        xh20 = \"SELECT * from extraHoursDetails\"\n",
    "        xh20 = pd.read_sql(xh20,engine)\n",
    "        sql = \"SELECT Distinct(Store) from structure_tab\"\n",
    "        st = pd.read_sql(sql,engine)\n",
    "        ## Create a Week Column and set to Week 1 ## \n",
    "        st['Week'] = 2101\n",
    "        st = pd.concat([st]*52)\n",
    "        st['Week'] = st.Week.add(st.groupby(['Store']).cumcount())\n",
    "        xh20ct = pd.merge(st,xh20[['Store','Week','Hours']],on=['Store','Week'],how='left').fillna(0)\n",
    "        xh20ct = pd.crosstab(xh20ct['Store'],xh20ct['Week'],xh20ct['Hours'],aggfunc='sum').reset_index()\n",
    "        xh20ct.columns = xh20ct.columns.astype(str)\n",
    "        xh20ct.to_sql('extraHours',con=engine,schema='dbo',if_exists='replace',index=False,dtype={'Store' : sa.types.VARCHAR(length=255)})\n",
    "        print(\"Added to SQL\")\n",
    "        print(\"CrossTab Updated\")\n",
    "        break\n",
    "    else:\n",
    "        print(\"Exiting Program, run this again to ADD to SQL.\")\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in Path(training_credits).glob('*.xlsx'):\n",
    "    shutil.move(str(file), os.path.join(str(file.parent) + '\\\\processed', str(file).split('\\\\')[-1]))\n",
    "    \n",
    "print(\"Training outputs moved into processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training outputs moved into processed.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
