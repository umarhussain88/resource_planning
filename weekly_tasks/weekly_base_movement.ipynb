{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "from pathlib import Path\n",
    "from time import sleep\n",
    "\n",
    "sys.path.append(\n",
    "    os.path.abspath(\n",
    "        r\"S:\\Data\\Stores Payroll\\FY21\\99_Master Scripts (DO NOT EDIT)\\dB_Connector\"))\n",
    "\n",
    "from connector import *\n",
    "\n",
    "sys.path.append(\n",
    "    os.path.abspath(\n",
    "        r\"S:\\Data\\Stores Payroll\\FY21\\99_Master Scripts (DO NOT EDIT)\\common_functions\"))\n",
    "\n",
    "from halfords_functions import newest, halfords_week\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weekly Base Movement\n",
    "\n",
    "* Change of Process for FY21\n",
    "\n",
    "* Use Colleauge File To Calc Base.\n",
    "\n",
    "* Get the budgets from the structure Tab.\n",
    "\n",
    "* devise a clever method so that we don't \n",
    "<ul>\n",
    "\n",
    "  <li>a) duplicate data</li>\n",
    "   <li> b) overwrite data</li>\n",
    "    <li>c) have a contigancy in place</li>\n",
    "\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fy21 dates.\n",
    "\n",
    "dates = pd.read_sql(\"SELECT * from fy21_calendar\", con=engine)\n",
    "\n",
    "# structure tab wtih shop names etc.\n",
    "\n",
    "structure = pd.read_sql(\"SELECT Shop as store, Base from structure_tab\", engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name,week_,day_ = halfords_week(dates)\n",
    "print(f\"We are {week_} weeks away from FY21\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_data = r'S:\\Data\\Stores Payroll\\FY21\\02_Weekly Tasks\\over & underBase Analysis\\raw_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_ = pd.read_excel(newest(base_data),skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Retail Shops.\n",
    "\n",
    "col_ = col_.loc[col_['Location Ledger Code'].isin(structure['store'])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Perm Only.\n",
    "\n",
    "col_ = col_.loc[col_['Contract Type'] == 'Permanent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_['status'] = np.where(col_['Normal Weekly Hours'] < 38.75, 'PT','FT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_ = col_.groupby([\"Location Ledger Code\", \"status\"]).agg(\n",
    "    {\"status\": \"count\", \"Normal Weekly Hours\": \"sum\"}\n",
    ").unstack(\"status\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_.columns = col_.columns.droplevel(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_.columns = ['store','FT', 'PT','FT Hours','PT Hours']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_['Hours'] = col_['FT Hours'] + col_['PT Hours'] # Calculate base hours.\n",
    "\n",
    "col_['Heads'] = col_['FT'] + col_['PT'] # Calculate base hours.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(col_,structure,on='store',how='left')\n",
    "\n",
    "df['Week'] = week_\n",
    "\n",
    "df['Year'] = 21\n",
    "\n",
    "current_cols = pd.read_sql(f\"SELECT TOP 1 * from weeklybasemovement\",engine).columns.tolist()\n",
    "\n",
    "df = df[['store','Heads','FT','PT','Base','Hours','Week','Year']]\n",
    "\n",
    "df.columns = current_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 0 to SQL for FY21\n"
     ]
    }
   ],
   "source": [
    "if len(pd.read_sql(f\"SELECT TOP 1 * from weeklybasemovement where week = {week_} and year = 21\",engine)) > 0:\n",
    "    print(f\"Week {week_} already exists in SQL, please check the data, ending the program here to stop any duplicates\")\n",
    "else:\n",
    "    print(f\"Adding {week_} to SQL for FY21\")\n",
    "    df.to_sql(\"weeklyBaseMovement\",engine,schema='dbo',if_exists='append',index=False,dtype=data_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_types = {'Location' : sa.types.VARCHAR(length=50)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql(\"SELECT * From [weeklyBaseMovement]\",engine)\n",
    "df['Position'] = df['Base'] - df['Hours']\n",
    "df['% Variance'] = (df['Base'] - df['Hours']) / df['Base']\n",
    "x = df['% Variance']\n",
    "\n",
    "conds = [ x <= -0.01, x >= 0.01]\n",
    "choices = ['overBase',\"underBase\"]\n",
    "df['Status'] = np.select(conds,choices,default='atBase')\n",
    "df.sort_values(['Year','Week','Store'],inplace=True)\n",
    "\n",
    "s=df.groupby('Store')['Status'].apply(lambda x : x.ne(x.shift()).ne(0).cumsum())\n",
    "df['Count']=df.groupby([df.Store,s]).cumcount()+1\n",
    "\n",
    "\n",
    "df['Position'] = df['Base'] - df['Hours']\n",
    "df['% Variance'] = (df['Base'] - df['Hours']) / df['Base']\n",
    "\n",
    "x = df['% Variance']\n",
    "\n",
    "conds = [ x <= -0.01, x >= 0.01]\n",
    "\n",
    "choices = ['overBase',\"underBase\"]\n",
    "\n",
    "df['Status'] = np.select(conds,choices,default='atBase')\n",
    "\n",
    "df.sort_values(['Year','Week','Store'],inplace=True)\n",
    "\n",
    "s=df.groupby('Store')['Status'].apply(lambda x : x.ne(x.shift()).ne(0).cumsum())\n",
    "\n",
    "df['Count']=df.groupby([df.Store,s]).cumcount()+1\n",
    "\n",
    "a = df.loc[(df.Week == int(week_-1)) & (df.Year == 21)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'S:\\Data\\Stores Payroll\\FY21\\02_Weekly Tasks\\over & underBase Analysis\\outputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(f\"{file_name}_over_&_under_base_analysis.xlsx\",)\n",
    "df.to_excel(writer,'Raw_Data',index=False)\n",
    "a.to_excel(writer,'Current Week',index=False)\n",
    "writer.save()\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in Path(base_data).glob('*.xlsx'):\n",
    "    file.rename(Path(file.parent, f\"{file_name}_{file.stem}{file.suffix}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in Path(base_data).glob('*.xlsx'):\n",
    "    shutil.move(str(file), os.path.join(str(file.parent) + '\\\\processed', str(file).split('\\\\')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
