{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "from pathlib import Path\n",
    "from time import sleep\n",
    "\n",
    "sys.path.append(\n",
    "    os.path.abspath(\n",
    "        r\"S:\\Data\\Stores Payroll\\FY21\\99_Master Scripts (DO NOT EDIT)\\dB_Connector\"))\n",
    "\n",
    "from connector import *\n",
    "\n",
    "sys.path.append(\n",
    "    os.path.abspath(\n",
    "        r\"S:\\Data\\Stores Payroll\\FY21\\99_Master Scripts (DO NOT EDIT)\\common_functions\"))\n",
    "\n",
    "from halfords_functions import newest, halfords_week\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fy21 dates.\n",
    "\n",
    "dates = pd.read_sql(\"SELECT * from fy21_calendar\", con=engine)\n",
    "\n",
    "# structure tab wtih shop names etc.\n",
    "\n",
    "structure = pd.read_sql(\"SELECT Shop as store, Base from structure_tab\", engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As today is 2019-09-26 we haven't started FY21 so we will be using a psuedo week number which is calculated\n",
      "from the distance of weeks from FY21\n",
      "We are -27 weeks away from FY21\n"
     ]
    }
   ],
   "source": [
    "file_name,week_,day_ = halfords_week(dates)\n",
    "print(f\"We are {week_} weeks away from FY21\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporary Colleague Calculator Update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1. Read in Latest Base Data.\\n2. read in latest colleague data data.\\n3. do some basic maniuplation and create a dataframe with one entry per col for each\\nweek in the year. (so 1 * 53)\\n4. Read in the Current SQL table.\\n5. Merge the Input, cDate, and Verification with a left join (this removes leavers and adds in starters)\\n6. for new starters, find these and change these to null values for our SQL dB.\\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "1. Read in Latest Base Data.\n",
    "2. read in latest colleague data data.\n",
    "3. do some basic maniuplation and create a dataframe with one entry per col for each\n",
    "week in the year. (so 1 * 53)\n",
    "4. Read in the Current SQL table.\n",
    "5. Merge the Input, cDate, and Verification with a left join (this removes leavers and adds in starters)\n",
    "6. for new starters, find these and change these to null values for our SQL dB.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_data = r'S:\\Data\\Stores Payroll\\FY21\\02_Weekly Tasks\\Temps\\raw_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_ = pd.read_excel(newest(col_data),skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_.rename(columns={'Location Ledger Code' : 'store'},inplace=True)\n",
    "\n",
    "col_['Full Name'] = col_['First Name'] + ' ' + col_['Last Name']\n",
    "\n",
    "col_= col_[['Full Name','Number','Normal Weekly Hours','store']].copy()\n",
    "\n",
    "col_ = col_.loc[col_['store'].isin(structure['store'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_['Week'] = 1\n",
    "\n",
    "col_ = pd.concat([col_]*52)\n",
    "\n",
    "col_.Week = col_.Week.add(col_.groupby('Number').cumcount())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = pd.read_sql(\"SELECT * from colleague_data\",engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = pd.merge(col_,inputs[['Number','cDate','Verification','Input','Week']],on=['Number','Week'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_week = inputs['Number'].nunique()\n",
    "today_c = new_cols['Number'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WoW we have seen a reduction of 548 colleagues\n"
     ]
    }
   ],
   "source": [
    "print(f\"WoW we have seen a reduction of {last_week - today_c} colleagues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_cols = new_cols[['Full Name', 'Number', 'Normal Weekly Hours', 'store', 'Input', 'Week',\n",
    "       'cDate', 'Verification']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nas Available Hours changes WoW due to extra hours,\\nand the base is updated to due to colleauges leaving and starting, we will write this into SQL each weeek.\\n\\nCurrently writing this in here.\\n\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "as Available Hours changes WoW due to extra hours,\n",
    "and the base is updated to due to colleauges leaving and starting, we will write this into SQL each weeek.\n",
    "\n",
    "Currently writing this in here.\n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ah = pd.read_sql('SELECT * from available_hours',engine)\n",
    "\n",
    "\n",
    "xh = pd.read_sql(\"SELECT Hours, Store, Week from extraHoursDetails\",engine)\n",
    "\n",
    "\n",
    "holsB = pd.read_sql(\"SELECT * from holiday_budget\",engine)\n",
    "\n",
    "\n",
    "ah = pd.melt(ah,id_vars='Store',var_name='Week',value_name='AH Hours')\n",
    "\n",
    "\n",
    "ah.Week = ah.Week.astype(int)\n",
    "\n",
    "\n",
    "xh = xh.groupby(['Store','Week'])['Hours'].sum().reset_index()\n",
    "\n",
    "\n",
    "hours = pd.merge(ah,xh,on=['Store','Week'],how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "base = pd.read_sql('SELECT * from weeklyBaseMovement where Year = 21',engine)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "hours.Store = hours.Store.astype(int)\n",
    "hours['Week'] = hours['Week'] - 2100\n",
    "\n",
    "\n",
    "hours = pd.merge(hours,base[['Store','Week','Base']],on=['Week','Store'],how='left')\n",
    "hours = hours.sort_values(['Store','Week'])\n",
    "\n",
    "\n",
    "hours['Base'] = hours['Base'].ffill()\n",
    "hours.Hours = hours['AH Hours'] + hours['Hours'].fillna(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "hours = hours.drop('AH Hours',axis=1)\n",
    "\n",
    "holsB = pd.melt(holsB,id_vars='Store',var_name='Week',value_name='Holiday Budget')\n",
    "holsB['Week'] = holsB['Week'].astype(int) - 2000\n",
    "\n",
    "holsB['Store'] = holsB['Store'].astype(int)\n",
    "hours = pd.merge(hours,holsB, on=['Store','Week'],how='left')\n",
    "\n",
    "hours.rename(columns={'Holiday Budget' : 'HolsB'},inplace=True)\n",
    "hours = hours.fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'S:\\Data\\Stores Payroll\\FY21\\02_Weekly Tasks\\Temps\\sql_extract')\n",
    "\n",
    "hours.to_csv(f'{file_name}_temp_poc.csv.gz',index=False,compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_cols.to_csv(f'0{file_name}_colleague_data.csv.gz',index=False,compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "hours.rename(columns={'Holiday Budget' : 'HolsB'},inplace=True)\n",
    "\n",
    "types = {'Store' : sa.types.BIGINT,\n",
    "        'Week' : sa.types.BIGINT,\n",
    "        'Hours' : sa.types.FLOAT,\n",
    "        'Base' : sa.types.FLOAT,\n",
    "         'HolsB' : sa.types.FLOAT}\n",
    "\n",
    "hours.to_sql('tempPOC',engine,schema='dbo',if_exists='replace',index=False,dtype=types)\n",
    "print(\"Complete\")\n",
    "\n",
    "\n",
    "types_2 = {'Full Name' : sa.types.VARCHAR(length=50),\n",
    "        'Number' : sa.types.BIGINT,\n",
    "        'Normal Weekly Hours' : sa.types.FLOAT,\n",
    "        'Shop' : sa.types.BIGINT,\n",
    "         'Input' : sa.types.FLOAT,\n",
    "         'Week' : sa.types.BIGINT,\n",
    "         'cDate' : sa.types.NVARCHAR(length=255),\n",
    "         'Verification' : sa.types.VARCHAR(length=50)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "new_cols.to_sql('ColData',engine,schema='dbo',if_exists='replace',index=False,dtype=types_2)\n",
    "print(\"Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in Path(col_data).glob('*.xlsx'):\n",
    "    file.rename(Path(file.parent, f\"{file_name}_{file.stem}{file.suffix}\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colleague Data moved into processed.\n"
     ]
    }
   ],
   "source": [
    "for file in Path(col_data).glob('*.xlsx'):\n",
    "    shutil.move(str(file), os.path.join(str(file.parent) + '\\\\processed', str(file).split('\\\\')[-1]))\n",
    "    \n",
    "print(\"Colleague Data moved into processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
