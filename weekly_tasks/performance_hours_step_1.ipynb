{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Hours and Sales #\n",
    "\n",
    "## FY21 Change Log##\n",
    "\n",
    "As there will no longer a performance calculator, or any visibility of weekly sales budgets and targets from resource planning, we will not need to maintain the data for the front end.\n",
    "\n",
    "* Performance Hours will be run weekly but only kept as a running quaterly log for shops.\n",
    "* Performance Hours will be displayed in the Deployment Dashboard (TBC) for AM's and DD's to view.\n",
    "\n",
    "* The Calcualtions for the Perf are as follows : \n",
    "\n",
    "For Each Category - Auto - Bike - Services : \n",
    "\n",
    "\n",
    "(Sales - Forecast) / 600 - for Auto\n",
    "(Sales - Forecast) / 200 - for Bike\n",
    "(Sales - Forecast) / 40 -  for Services\n",
    "\n",
    "These are then aggregated into a total performance number and the awarded or deducted on the following conditions: \n",
    "\n",
    "* If the Perfomance hours are < 0 but the Total Forecast was hit then no hours area taken.\n",
    "* If the Performance Hours are >= 0 then these are awarded to the shop. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "from pathlib import Path\n",
    "from time import sleep\n",
    "\n",
    "sys.path.append(\n",
    "    os.path.abspath(\n",
    "        r\"S:\\Data\\Stores Payroll\\FY21\\99_Master Scripts (DO NOT EDIT)\\dB_Connector\"))\n",
    "\n",
    "from connector import *\n",
    "\n",
    "sys.path.append(\n",
    "    os.path.abspath(\n",
    "        r\"S:\\Data\\Stores Payroll\\FY21\\99_Master Scripts (DO NOT EDIT)\\common_functions\"))\n",
    "\n",
    "from halfords_functions import newest, halfords_week\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fy21 dates.\n",
    "\n",
    "dates = pd.read_sql(\"SELECT * from fy21_calendar\", con=engine)\n",
    "\n",
    "# structure tab wtih shop names etc.\n",
    "\n",
    "structure = pd.read_sql(\"SELECT Shop as store, Base from structure_tab\", engine)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As today is 2019-09-26 we haven't started FY21 so we will be using a psuedo week number which is calculated\n",
      "from the distance of weeks from FY21\n",
      "We are -27 weeks away from FY21\n"
     ]
    }
   ],
   "source": [
    "file_name,week_,day_ = halfords_week(dates)\n",
    "print(f\"We are {week_} weeks away from FY21\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Budgets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_budgets = ['auto_budgets','bike_budgets','service_budgets']\n",
    "\n",
    "# read, melt and merge into a tabular format by reading each table into a dict.\n",
    "\n",
    "\n",
    "data = {}\n",
    "# could do this as a liner with list-comp but this is more readable imo. \n",
    "\n",
    "for category in sales_budgets:\n",
    "    df = pd.read_sql(f\"SELECT * from {category}\",engine) \n",
    "    df_melt = pd.melt(df,id_vars='Store',var_name='Week',value_name=f'{category}') \n",
    "    data[f'{category}'] = df_melt\n",
    "\n",
    "\n",
    "# merge.     \n",
    "df = pd.merge(data['auto_budgets'],data['service_budgets'],on=['Week','Store'],how='left')\n",
    "\n",
    "budget = pd.merge(df,data['bike_budgets'],on=['Week','Store'],how='left')\n",
    "\n",
    "budget['Total'] = budget.iloc[:,2:].sum(axis=1) # row wise sum. \n",
    "\n",
    "budget = pd.melt(budget,id_vars=['Store','Week'],var_name='Category',value_name='Budget')\n",
    "\n",
    "d_ = ['Auto','Bikes','Services']\n",
    "di_ = dict(zip(sales_budgets,d_))\n",
    "\n",
    "\n",
    "budget['Category'] = budget['Category'].map(di_).fillna('Total') # Map Budgets to match Actuals Name for Merge. \n",
    "\n",
    "budget['Week'] = budget['Week'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Actuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = r'S:\\Data\\Stores Payroll\\FY21\\02_Weekly Tasks\\Actual Sales - Performance Hours\\raw_sales_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "actuals = pd.read_excel(newest(raw_data),sheet_name='Table',skiprows=15).iloc[:-1,6:].drop('Unnamed: 7',axis=1)\n",
    "actuals_week = pd.read_excel(newest(raw_data),sheet_name='Table',skiprows=14).iloc[:,8:9].columns.tolist()\n",
    "actuals_year =  re.findall(r'(\\d+)',actuals_week[0])[1]\n",
    "actuals_week = re.findall(r'(^\\d+)',actuals_week[0])\n",
    "actuals.rename(columns = {'Site' : 'Store'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_stores = actuals['Store'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The week listed in this file is 25 and the year listed is 2019\n",
      "there are 447 stores in this file\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "f\"\"\"The week listed in this file is {int(actuals_week[0])} and the year listed is {actuals_year}\n",
    "there are {unique_stores} stores in this file\"\"\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2125"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "actuals['Week'] = int(actuals_week[0]) + 2100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "actuals_ = pd.melt(actuals,id_vars=['Store','Week'],var_name='Category',value_name='Actual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf = pd.merge(actuals_,budget,on=['Store','Week','Category'],how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Min & Variable Perf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_perf = pd.read_sql(\"SELECT * FROM min_perf\",engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_week = int(actuals_week[0]) + 2100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Week 2125 for Variable Hours\n"
     ]
    }
   ],
   "source": [
    "print(f\"Reading Week {sql_week} for Variable Hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = pd.read_sql(f\"SELECT Store, {[sql_week]} as variable from variable_hours\",engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalPerf = perf.loc[perf['Category'] == 'Total'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_lookups = pd.merge(min_perf,variable,on='Store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalPerf = pd.merge(finalPerf,perf_lookups,on='Store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Perf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workout Individual Perf.\n",
    "\n",
    "perf = perf.loc[perf['Category'] != 'Total'].copy()\n",
    "\n",
    "perf.loc[perf.Category == 'Bikes','Perf'] = (perf['Actual'] - perf['Budget'])/200\n",
    "perf.loc[perf.Category == 'Services','Perf'] = (perf['Actual'] - perf['Budget'])/40\n",
    "perf.loc[perf.Category == 'Auto','Perf'] = (perf['Actual'] - perf['Budget'])/600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a grouped dataframe with the totals.\n",
    "\n",
    "\n",
    "\n",
    "finalPerf = pd.merge(\n",
    "    finalPerf,\n",
    "    perf.groupby([\"Store\"])[\"Perf\"].sum().reset_index(),\n",
    "    on=[\"Store\"],\n",
    "    how=\"left\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\n",
    "    (finalPerf[\"Actual\"] > finalPerf[\"Budget\"]) & (finalPerf[\"Perf\"] < 0),\n",
    "    (finalPerf[\"Perf\"] > 0) & (finalPerf[\"Budget\"] > finalPerf[\"Actual\"]),\n",
    "    (finalPerf[\"Perf\"] >= 0),\n",
    "    (finalPerf[\"Perf\"] < finalPerf[\"variable\"])\n",
    "    & (finalPerf[\"variable\"] > finalPerf[\"min_perf\"]),\n",
    "    (finalPerf[\"min_perf\"] > finalPerf[\"Perf\"])\n",
    "    & (finalPerf[\"min_perf\"] > finalPerf[\"variable\"]),\n",
    "    (finalPerf[\"Perf\"] > finalPerf[\"min_perf\"])\n",
    "    & (finalPerf[\"Perf\"] > finalPerf[\"variable\"]),\n",
    "]\n",
    "\n",
    "\n",
    "outputs = [\n",
    "    0,\n",
    "    finalPerf[\"Perf\"],\n",
    "    finalPerf[\"Perf\"],\n",
    "    finalPerf[\"variable\"],\n",
    "    finalPerf[\"min_perf\"],\n",
    "    finalPerf[\"Perf\"],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalPerf['Actual Perf'] = np.select(conditions,outputs,default=finalPerf['Perf'])\n",
    "\n",
    "\n",
    "finalPerf['Actual Perf'] = np.ceil(finalPerf['Actual Perf']*4)/4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'S:\\Data\\Stores Payroll\\FY21\\02_Weekly Tasks\\Actual Sales - Performance Hours\\outputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "writer = pd.ExcelWriter(file_name + 'Performance_Hours.xlsx')\n",
    "finalPerf.to_excel(writer,'Total_Perf',index=False)\n",
    "perf.to_excel(writer,'Performance_Category',index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I/O Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in Path(raw_data).glob('*.xlsm'):\n",
    "    file.rename(Path(file.parent, f\"{file_name}_{file.stem}{file.suffix}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in Path(raw_data).glob('*.xlsm'):\n",
    "    shutil.move(str(file), os.path.join(str(file.parent) + '\\\\processed', str(file).split('\\\\')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
