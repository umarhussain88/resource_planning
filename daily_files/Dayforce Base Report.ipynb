{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master Script for FY21 Hours Used & Holiday Spend. \n",
    "\n",
    "\n",
    "Steps as follows \n",
    "\n",
    "* Simple script that wrangles data into 3 outputs:\n",
    "* Hours Used - Holiday Spent - PayCodeDetail (this is the detail behind the hours used table)\n",
    "\n",
    "* Code will be documented for readability - as data is very small only takes 3-5 seconds to create all three tables & \n",
    "* write to SQL. \n",
    "\n",
    "* We take a extract of every table for risk and to measure daily changes.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "from pathlib import Path\n",
    "from time import sleep\n",
    "\n",
    "sys.path.append(\n",
    "    os.path.abspath(\n",
    "        r\"S:\\Data\\Stores Payroll\\FY21\\99_Master Scripts (DO NOT EDIT)\\dB_Connector\"))\n",
    "\n",
    "from connector import *\n",
    "\n",
    "sys.path.append(\n",
    "    os.path.abspath(\n",
    "        r\"S:\\Data\\Stores Payroll\\FY21\\99_Master Scripts (DO NOT EDIT)\\common_functions\"))\n",
    "\n",
    "from halfords_functions import newest, add_years, halfords_week\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in relevant tables : \n",
    "\n",
    "* fy21 Calendar \n",
    "* Structure Tab\n",
    "* pay_code lookups. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fy21 dates.\n",
    "\n",
    "dates = pd.read_sql(\"SELECT * from fy21_calendar\", con=engine)\n",
    "\n",
    "# structure tab wtih shop names etc.\n",
    "\n",
    "structure = pd.read_sql(\"SELECT Shop as store from structure_tab\", engine)\n",
    "\n",
    "# paycodes = payCodeLookups\n",
    "\n",
    "paycodes = pd.read_sql(\"SELECT * from paycodes\", engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name,week_,day_ = halfords_week(dates)\n",
    "print(f\"We are {week_} weeks away from FY21\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Newest Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_report_path = (\n",
    "    r\"S:\\Data\\Stores Payroll\\FY21\\01_Daily Tasks\\Dayforce Base Report\\Raw Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read in Report and set column names, then drop the last column, not sure why this keeps reading in.. \n",
    "\n",
    "base_report = pd.read_excel(\n",
    "    newest(base_report_path),\n",
    "    header=None,\n",
    "    skiprows=2,\n",
    "    names=[\"date\", \"store\", \"pay_code\", \"hours\", \"\"]\n",
    ")\n",
    "\n",
    "base_report = base_report.iloc[:,:-1]\n",
    "\n",
    "# set date time column.  \n",
    "\n",
    "base_report['date'] = pd.to_datetime(base_report['date'],dayfirst=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inner join to only return matches, we don't care about data outside of the Financial Year.\n",
    "\n",
    "paycode_hours = pd.merge(base_report,dates,on='date',how='inner')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add in paycodes and whether we use them for calculations - Ideally this should be redone with Finance input so\n",
    "# we are aligned with the business spend. \n",
    "\n",
    "paycode_hours = pd.merge(\n",
    "    paycode_hours, paycodes[['dfpaycode', 'title', 'timesheet', 'add', 'deduct',\n",
    "       'exclude', 'holadd', 'holded']], left_on=\"pay_code\", right_on=\"dfpaycode\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change negative values to positive, \n",
    "## some store managers enter in negative values for timesheet entries.. no validation on DF. \n",
    "\n",
    "paycode_hours['hours'] = abs(paycode_hours['hours']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## we now split out the single dataframe into two, I could make this more elegant by changing the \n",
    "## paycode table, don't have time for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Create Deduct & Hoursused Tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use the timesheet column & deduct column to break out the hours spend & deductions. \n",
    "\n",
    "hours_spend = (\n",
    "    paycode_hours.loc[paycode_hours[\"timesheet\"] == \"Y\"]\n",
    "    .groupby([\"store\", \"retail_ops_week\"])[\"hours\"]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deduct_spend = (\n",
    "    paycode_hours.loc[paycode_hours[\"deduct\"] == \"Y\"]\n",
    "    .groupby([\"store\", \"retail_ops_week\"])[\"hours\"]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets merge these now and rename the columns.\n",
    "\n",
    "hours_spend_summary = pd.merge(\n",
    "    hours_spend, deduct_spend, on=[\"store\", \"retail_ops_week\"], how=\"left\"\n",
    ").rename(columns={\"hours_y\": \"deduct_hours\", \"hours_x\": \"hours\"}).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Total Hours Charged \n",
    "\n",
    "## the deductions are agreed business rules between ops & the people team in regards to what we backfill & what we don't.\n",
    "## the holiday spend is accounted for in the holiday budget so not charged to their available hours. (or worked hours.)\n",
    "\n",
    "hours_spend_summary[\"total_hours_charged\"] = (\n",
    "    hours_spend_summary[\"hours\"] - hours_spend_summary[\"deduct_hours\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 -  Leaver Holiday Deductions LHOD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is a lengthy script - and is only done weekly, but we need to account for it daily.\n",
    "\n",
    "## We read in the latest file from the LHOD area - and calculate it here.\n",
    "\n",
    "lhod_path = r\"S:\\Data\\Stores Payroll\\FY21\\02_Weekly Tasks\\LHOD\\outputs\"\n",
    "\n",
    "lhod = pd.read_excel(newest(lhod_path), sheet_name=-1)\n",
    "\n",
    "lhod.columns = ['retail_ops_week','store','dfpaycode','pay_code','hours']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets concat this to our main_paycode dataframe to work out the holiday & deductions. \n",
    "\n",
    "paycode_hours = pd.concat(\n",
    "    [\n",
    "        paycode_hours[[\"retail_ops_week\", \"store\", \"dfpaycode\", \"pay_code\", \"hours\"]],\n",
    "        lhod,\n",
    "    ]\n",
    ").copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 - Holiday Time #\n",
    "\n",
    "## Calculate Holiday Hours with PayCodes ## \n",
    "\n",
    "* Changes from FY19\n",
    "* This will include HOLC which wasn't included in FY19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the paycode deduct data again. \n",
    "\n",
    "paycode_hours = (\n",
    "    pd.merge(\n",
    "        paycode_hours,\n",
    "        paycodes[\n",
    "            [\n",
    "                \"dfpaycode\",\n",
    "                \"title\",\n",
    "                \"timesheet\",\n",
    "                \"add\",\n",
    "                \"deduct\",\n",
    "                \"exclude\",\n",
    "                \"holadd\",\n",
    "                \"holded\",\n",
    "            ]\n",
    "        ],\n",
    "        left_on=\"pay_code\",\n",
    "        right_on=\"dfpaycode\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "    .drop(\"dfpaycode_y\", axis=1)\n",
    "    .rename(columns={\"dfpaycode_x\": \"dfpaycode\"})\n",
    "    .copy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday = (\n",
    "    paycode_hours.loc[paycode_hours[\"holadd\"] == \"Y\"] \n",
    "    .groupby([\"retail_ops_week\", \"store\"])[\"hours\"]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"hours\": \"holiday_hours\"})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaver_hol = (\n",
    "    paycode_hours.loc[paycode_hours[\"holded\"] == \"Y\"]\n",
    "    .groupby([\"retail_ops_week\", \"store\"])[\"hours\"]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"hours\": \"lhod_hours\"})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Step - Create the SQL Tables and File I/O Operations. \n",
    "\n",
    "* Create SQL Tables\n",
    "* Save file down to relevant areas.\n",
    "* Move file from raw data to processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## All - Hours. \n",
    "\n",
    "final_hours = pd.merge(hours_spend_summary, structure, on=\"store\", how=\"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_hours = (\n",
    "    pd.merge(final_hours, holiday, on=[\"store\", \"retail_ops_week\"], how=\"left\")\n",
    "    .fillna(0)\n",
    "    .copy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_hours = (\n",
    "    pd.merge(final_hours, leaver_hol, on=[\"store\", \"retail_ops_week\"], how=\"left\")\n",
    "    .fillna(0)\n",
    "    .copy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Workout Total Holiday Hours for Holiday CrossTab.\n",
    "\n",
    "final_hours[\"total_holiday_hours\"] = (\n",
    "    final_hours[\"holiday_hours\"] - final_hours[\"lhod_hours\"]\n",
    ")\n",
    "\n",
    "final_hours['retail_ops_week'] = final_hours['retail_ops_week'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours_used_ct = pd.concat([structure]*52)\n",
    "\n",
    "hours_used_ct[\"retail_ops_week\"] = 2101\n",
    "\n",
    "hours_used_ct[\"retail_ops_week\"] = hours_used_ct[\"retail_ops_week\"].add(\n",
    "    hours_used_ct.groupby([\"store\"]).cumcount()\n",
    ")\n",
    "\n",
    "# Create a blank dataframe with everyshop for every week of the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours_used_ct = pd.merge(\n",
    "    hours_used_ct,\n",
    "    final_hours[[\"store\", \"retail_ops_week\", \"total_hours_charged\"]],\n",
    "    on=[\"store\", \"retail_ops_week\"],how='left'\n",
    ").fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hours Used Crosstabs.\n",
    "\n",
    "\n",
    "hours_used_ct = (\n",
    "    pd.crosstab(\n",
    "        hours_used_ct[\"store\"],\n",
    "        hours_used_ct[\"retail_ops_week\"],\n",
    "        hours_used_ct[\"total_hours_charged\"],\n",
    "        aggfunc=\"sum\",\n",
    "    )\n",
    "    .reset_index()\n",
    "    .fillna(0)\n",
    ")\n",
    "\n",
    "\n",
    "hours_used_ct[\"store\"] = hours_used_ct[\"store\"].astype(int).astype(str).str.zfill(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours_used_ct.rename(columns={'store' : 'Store'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save file down : \n",
    "\n",
    "os.chdir(r\"S:\\Data\\Stores Payroll\\FY21\\01_Daily Tasks\\Dayforce Base Report\\HoursUsed FY20\")\n",
    "\n",
    "\n",
    "hours_used_ct.to_excel(f\"{file_name}_hours_used.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paycode Table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paycode_list = pd.DataFrame(paycodes.dropna(subset=['dfpaycode'])['dfpaycode'].tolist()) \n",
    "\n",
    "# generate a list of dayforce paycodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure['retail_ops_week'] = 2101 \n",
    "\n",
    "# set week to one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## awesome line of code, does a caretesian join to create a paycode entry for every store for week 1. \n",
    "\n",
    "paycode_detail = structure.assign(a=1).merge(paycode_list.assign(a=1)).drop(\"a\", 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 22 * 450 is 9900 is the code did as expected. - we do this as asp-classic/sql needs to an entry for every potential value\n",
    "## even if that value is 0. \n",
    "\n",
    "paycode_detail = pd.concat([paycode_detail]*52) # create an entry for every week in the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paycode_detail.rename(columns={0 : 'dfpaycode'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paycode_detail[\"retail_ops_week\"] = paycode_detail[\"retail_ops_week\"].add(\n",
    "    paycode_detail.groupby([\"store\", \"dfpaycode\"]).cumcount()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paycode_d = paycode_hours.groupby([\"store\", \"dfpaycode\", \"retail_ops_week\"])[\n",
    "    \"hours\"\n",
    "].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paycode_detail = (\n",
    "    pd.merge(\n",
    "        paycode_detail,\n",
    "        paycode_d,\n",
    "        on=[\"store\", \"dfpaycode\", \"retail_ops_week\"],\n",
    "        how=\"left\",\n",
    "    )\n",
    "    .fillna(0)\n",
    "    .copy()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PayCode Detail ##\n",
    "## this is just a groupby on the Analysis Table ##\n",
    "\n",
    "\n",
    "## Create CrossTab ##\n",
    "paycode_details = (\n",
    "    pd.crosstab(\n",
    "        [paycode_detail[\"store\"], paycode_detail[\"retail_ops_week\"]],\n",
    "        paycode_detail[\"dfpaycode\"],\n",
    "        paycode_detail[\"hours\"],\n",
    "        aggfunc=sum,\n",
    "    )\n",
    "    .fillna(0)\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paycode_details = (\n",
    "    pd.merge(paycode_details, final_hours, on=[\"store\", \"retail_ops_week\"], how=\"left\")\n",
    "    .fillna(0)\n",
    "    .copy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set metadata type for SQL Server ##\n",
    "\n",
    "\n",
    "\n",
    "paycode_details[\"holiday_hours\"] = paycode_details[\"HOL\"]\n",
    "paycode_details[\"Leaver Holiday Pay\"] = paycode_details[\"LHOP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paycode_details.rename(columns={'hours' : 'Actual Dayforce Spend',\n",
    "                               'deduct_hours' : 'deductHours',\n",
    "                               'total_hours_charged' : 'Total Hours charged',\n",
    "                               'holiday_hours' : \"Holiday Hours\",\n",
    "                               'lhod_hours' : \"Leaver Holiday Deducts\",\n",
    "                               'total_holiday_hours' : 'Total Holiday Hours',\n",
    "                               'store' : 'Store',\n",
    "                               'retail_ops_week' : 'YearWeek'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    \"Store\",\n",
    "    \"YearWeek\",\n",
    "    \"FERTILITY TREATMENT\",\n",
    "    \"BRK\",\n",
    "    \"AUTHORISED UNPAID ABSENCE\",\n",
    "    \"BEREAVEMENT\",\n",
    "    \"EMERGENCY FAMILY LEAVE\",\n",
    "    \"ADOPTION\",\n",
    "    \"HOL\",\n",
    "    \"HOLC\",\n",
    "    \"JURY SERVICE\",\n",
    "    \"MATERNITY\",\n",
    "    \"MEDICAL APPOINTMENT\",\n",
    "    \"OFFSITE OR TRAINING\",\n",
    "    \"PATERNITY\",\n",
    "    \"SHARED PARENTAL LEAVE\",\n",
    "    \"SICKNESS\",\n",
    "    \"SUSPENSION\",\n",
    "    \"TIME OUT\",\n",
    "    \"UNAUTHORISED UNPAID ABSENCE\",\n",
    "    \"TA RESERVIST\",\n",
    "    \"WRK\",\n",
    "    \"LHOD\",\n",
    "    \"LHOP\",\n",
    "    \"Actual Dayforce Spend\",\n",
    "    \"deductHours\",\n",
    "    \"Total Hours charged\",\n",
    "    \"Holiday Hours\",\n",
    "    \"Leaver Holiday Deducts\",\n",
    "    \"Leaver Holiday Pay\",\n",
    "    \"Total Holiday Hours\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "paycode_details = paycode_details[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paycode_details['Store'] = paycode_details['Store'].astype(int).astype(str).str.zfill(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'S:\\Data\\Stores Payroll\\FY21\\01_Daily Tasks\\Dayforce Base Report\\PayCodeDetail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paycode_details.to_excel(f\"{file_name}_paycode_detail.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Holiday Crosstab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_ct = pd.concat([structure]*52)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_ct[\"retail_ops_week\"] = holiday_ct[\"retail_ops_week\"].add(\n",
    "    holiday_ct.groupby([\"store\"]).cumcount()\n",
    ")\n",
    "\n",
    "# Create a blank dataframe with everyshop for every week of the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_ct = (\n",
    "    pd.merge(\n",
    "        holiday_ct,\n",
    "        final_hours[[\"store\", \"retail_ops_week\", \"total_holiday_hours\"]],\n",
    "        on=[\"store\", \"retail_ops_week\"],\n",
    "        how=\"left\",\n",
    "    ).fillna(0)\n",
    ").copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_ct_final = pd.crosstab(\n",
    "    holiday_ct[\"store\"],\n",
    "    holiday_ct[\"retail_ops_week\"],\n",
    "    holiday_ct[\"total_holiday_hours\"],\n",
    "    aggfunc=\"sum\",\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_ct_final[\"store\"] = (\n",
    "    holiday_ct_final[\"store\"].astype(int).astype(str).str.zfill(4)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_ct_final.rename(columns={'store' : 'Store'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save file down \n",
    "\n",
    "\n",
    "# save file down : \n",
    "\n",
    "os.chdir(r\"S:\\Data\\Stores Payroll\\FY21\\01_Daily Tasks\\Dayforce Base Report\\Holiday Taken\")\n",
    "\n",
    "holiday_ct_final.to_excel(f\"{file_name}_holiday_taken.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write to SQL and move raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write this to SQL\n",
    "\n",
    "## Set meta_type TEXT is depcreiated in SQL server and gives errors.\n",
    "\n",
    "dtypes = {\"Store\": sa.types.VARCHAR(length=50)}\n",
    "\n",
    "hours_used_ct.to_sql(\n",
    "    \"hours_used\",\n",
    "    con=engine,\n",
    "    schema=\"dbo\",\n",
    "    index=False,\n",
    "    dtype=dtypes,\n",
    "    if_exists=\"replace\",\n",
    ")\n",
    "\n",
    "print(f\"Hi {os.getlogin()}, the hours_used table has been updated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_ct_final.to_sql(\n",
    "    \"holiday_spend\", con=engine, schema=\"dbo\", index=False, dtype=dtypes, if_exists=\"replace\"\n",
    ")\n",
    "\n",
    "print(\"holiday_tab detail updated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paycode_details.to_sql(\n",
    "    \"paycode_detail\",\n",
    "    con=engine,\n",
    "    schema=\"dbo\",\n",
    "    index=False,\n",
    "    dtype=dtypes,\n",
    "    if_exists=\"replace\",\n",
    ")\n",
    "\n",
    "print(\"pay_code detail updated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_path = r'S:\\Data\\Stores Payroll\\FY21\\01_Daily Tasks\\Dayforce Base Report\\Raw Data\\processed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in Path(base_report_path).glob('*.xlsx'):\n",
    "    file.rename(Path(file.parent, f\"{file_name}_{file.stem}{file.suffix}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in Path(base_report_path).glob('*.xlsx'):\n",
    "    shutil.move(str(file), os.path.join(str(file.parent) + '\\\\processed', str(file).split('\\\\')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
