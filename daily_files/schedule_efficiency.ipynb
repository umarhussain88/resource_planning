{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "from pathlib import Path\n",
    "from time import sleep\n",
    "\n",
    "sys.path.append(\n",
    "    os.path.abspath(\n",
    "        r\"S:\\Data\\Stores Payroll\\FY21\\99_Master Scripts (DO NOT EDIT)\\dB_Connector\"))\n",
    "\n",
    "from connector import *\n",
    "\n",
    "sys.path.append(\n",
    "    os.path.abspath(\n",
    "        r\"S:\\Data\\Stores Payroll\\FY21\\99_Master Scripts (DO NOT EDIT)\\common_functions\"))\n",
    "\n",
    "from halfords_functions import newest, add_years, halfords_week\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schedule Efficiency #\n",
    "\n",
    "## Finalised and Agreed ##\n",
    "\n",
    "02/04/19\n",
    "\n",
    "* Format finalised script does as follows\n",
    "\n",
    "* Reads in latest file from raw data in Schedule Efficiency\n",
    "\n",
    "* as all scores are pre-calcualted from DF we essentially create an empty frame for every shop for every week of the year.\n",
    "\n",
    "* we merge in the schedule efficiency report and any missing values (Where shops have not published rotas) are coded as 0\n",
    "\n",
    "* we calculate the unplanned week from the current week + 4.\n",
    "\n",
    "* we save files down for Retail Finance on Friday's & Monday's.\n",
    "\n",
    "--\n",
    "\n",
    "Damian & Umar have agreed this. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Read in Dates & Store's.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fy21 dates.\n",
    "\n",
    "dates = pd.read_sql(\"SELECT * from fy21_calendar\", con=engine)\n",
    "\n",
    "# structure tab wtih shop names etc.\n",
    "\n",
    "structure = pd.read_sql(\"SELECT Shop as store, Location, Area, Division from structure_tab\", engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As today is 2019-09-24 we haven't started FY21 so we will be using a psuedo week number which is calculated\n",
      "from the distance of weeks from FY21\n",
      "We are -27 weeks away from FY21\n"
     ]
    }
   ],
   "source": [
    "file_name,week_,day_ = halfords_week(dates)\n",
    "unplanned_week = week_ + 4\n",
    "print(f\"We are {week_} weeks away from FY21\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The current unplanned week is {unplanned_week}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se = schedule_efficiency\n",
    "\n",
    "se_path_daily = r\"S:\\Data\\Stores Payroll\\FY21\\01_Daily Tasks\\Schedule Efficiency\\raw_data\\daily_files\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    se_daily = pd.read_excel(newest(se_path_daily),skiprows=1,parse_dates=['Week'])\n",
    "except PermissionError:\n",
    "    print(\"There are no files in this folder, skiping this step. If there is a file, hit refresh in your windows console,\\n or make a copy of the file, at times there are caching errors on windows machines.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_use = ['Location', 'Week', 'Zone', 'Schedule Efficiency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se_daily = se_daily[columns_to_use].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se_daily[\"store\"] = se_daily[\"Location\"].str.extract(\"(\\d+)\").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se_daily.rename(columns={'Week' : 'date'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se_daily = pd.merge(se_daily,dates,on='date',how='left').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se_daily[\"Schedule Efficiency\"] = (\n",
    "    se_daily[\"Schedule Efficiency\"].str[:5].astype(float).divide(100).fillna(0)\n",
    ").copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "structure['retail_ops_week'] = 2101\n",
    "\n",
    "structure = pd.concat([structure]*52)\n",
    "\n",
    "structure[\"retail_ops_week\"] = structure[\"retail_ops_week\"].add(structure.groupby([\"store\"]).cumcount())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se_daily = pd.merge(\n",
    "    structure, se_daily[[\"store\", \"Schedule Efficiency\", \"retail_ops_week\"]], how=\"left\"\n",
    ").fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se_daily_ct = pd.crosstab(\n",
    "    se_daily[\"store\"],\n",
    "    se_daily[\"retail_ops_week\"],\n",
    "    se_daily[\"Schedule Efficiency\"],\n",
    "    aggfunc=\"sum\",\n",
    ").reset_index()\n",
    "\n",
    "se_daily_ct[\"store\"] = se_daily_ct[\"store\"].astype(int).astype(str).str.zfill(4)\n",
    "\n",
    "dtypes = {'Store' : sa.types.VARCHAR(length=50)}\n",
    "\n",
    "se_daily_ct.rename(columns={'store' : 'Store'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se_daily_ct.to_sql('schedule_efficiency',con=engine,if_exists='replace',index=False,dtype=dtypes)\n",
    "\n",
    "print(\"Schedule Efficiency Updated on SQL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unplanned_hours = se_daily.loc[\n",
    "    (se_daily[\"retail_ops_week\"] == unplanned_week + 2100)\n",
    "    & (se_daily[\"Schedule Efficiency\"] == 0)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'S:\\Data\\Stores Payroll\\FY21\\01_Daily Tasks\\Schedule Efficiency\\daily_reports')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(f'{file_name}schedule_efficiency.xlsx')\n",
    "se_daily_ct.to_excel(writer,'se_crosstab',index=False)\n",
    "unplanned_hours.to_excel(writer,'unplanned_stores',index=False)\n",
    "writer.save()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weekly Pitstop Files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_path = r\"S:\\Data\\Stores Payroll\\FY21\\01_Daily Tasks\\Schedule Efficiency\\raw_data\\weekly_files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se_weekly = pd.read_excel(newest(weekly_path),skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se_weekly[\"Efficiency Score\"] = (\n",
    "    se_weekly[\"Efficiency Score\"].str[:5].astype(float).divide(100).fillna(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se_weekly['Location'] = se_weekly['Location'].str.extract('(\\d+)').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se_weekly.drop(['Unnamed: 4','Zone'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se_weekly['DayId'] = pd.to_datetime(se_weekly['DayId'],dayfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se_weekly.columns = ['store','date','score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se_weekly = pd.merge(se_weekly,dates,on='date',how='inner').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure['posting_day'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure = pd.concat([structure]*7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure[\"posting_day\"] = structure[\"posting_day\"].add(\n",
    "    structure.groupby([\"store\", \"retail_ops_week\"]).cumcount()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se_weekly_final = pd.merge(\n",
    "    structure, se_weekly, on=[\"store\", \"retail_ops_week\", \"posting_day\"], how=\"left\"\n",
    ").fillna(0).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitstop = se_weekly_final.loc[(se_weekly_final[\"retail_ops_week\"] == week_ + 2100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pit_stop = pitstop[['store','retail_ops_week','day','score']]\n",
    "\n",
    "se_daily_pitstop = se_daily[['store','retail_ops_week','Schedule Efficiency']].copy()\n",
    "se_daily_pitstop = se_daily_pitstop.loc[se_daily_pitstop['retail_ops_week'] == week_ + 2100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'S:\\Data\\Stores Payroll\\FY21\\01_Daily Tasks\\Schedule Efficiency\\pitstop_reports')\n",
    "\n",
    "writer = pd.ExcelWriter(file_name + 'pitstop.xlsx')\n",
    "pit_stop.to_excel(writer,'daily_scores',index=False)\n",
    "se_daily_pitstop.to_excel(writer,'week_score',index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [weekly_path,se_path_daily]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in paths:\n",
    "    for file in Path(file).glob('*.xlsx'):\n",
    "        file.rename(Path(file.parent, f\"{file_name}_{file.stem}{file.suffix}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for files in paths:\n",
    "    for file in Path(files).glob('*.xlsx'):\n",
    "        print('Moving',str(file).split('\\\\')[-1])\n",
    "        shutil.move(str(file), os.path.join(files + '\\\\processed', str(file).split('\\\\')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
